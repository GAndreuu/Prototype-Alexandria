# ğŸ›ï¸ Alexandria - Local AI Synthesis

<div align="center">

![Status](https://img.shields.io/badge/status-production-success?style=for-the-badge)
![Python](https://img.shields.io/badge/python-3.10+-blue?style=for-the-badge&logo=python)
![License](https://img.shields.io/badge/license-MIT-green?style=for-the-badge)

**SÃ­ntese Local de IA atravÃ©s de Aprendizado NÃ£o-Supervisionado**

*A cognitive architecture for local, self-improving AI systems*

[Objetivos](#-objetivos) â€¢ [Como Funciona](#-como-funciona) â€¢ [Teorias](#-fundamentos-teÃ³ricos) â€¢ [DocumentaÃ§Ã£o](#-documentaÃ§Ã£o)

</div>

---

## ğŸ¯ Objetivos

Alexandria busca criar uma **sÃ­ntese local de IA** atravÃ©s de:

1. **Autonomia Total**: Zero dependÃªncias de serviÃ§os cloud ou APIs externas
2. **Aprendizado ContÃ­nuo**: Sistema que se aperfeiÃ§oa com cada observaÃ§Ã£o
3. **RaciocÃ­nio Emergente**: InteligÃªncia que surge de processos bio-inspirados simples
4. **TransparÃªncia**: VisualizaÃ§Ã£o completa dos processos internos de decisÃ£o
5. **EficiÃªncia**: CompressÃ£o neural radical (96%) para operar localmente

**VisÃ£o**: Uma IA autÃ´noma e auto-aperfeiÃ§oante que roda na sua mÃ¡quina, sem cloud, sem censura, sem custo operacional.

---

## ğŸ“– A HistÃ³ria do Sistema

Alexandria comeÃ§ou como um experimento em **composicionalidade semÃ¢ntica**: serÃ¡ que cÃ³digos discretos podem raciocinar como embeddings contÃ­nuos?

A resposta foi surpreendente: **sim, mas de forma fundamentalmente diferente**.

### EvoluÃ§Ã£o

1. **Fase I**: RAG bÃ¡sico com LanceDB
2. **Fase II**: VQ-VAE para compressÃ£o neural
3. **Fase III**: Mycelial Network (Hebbian learning)
4. **Fase IV**: Nemesis Core (Active Inference + Predictive Coding)
5. **Fase V**: Pre-Structural Field (Geometria Diferencial)
6. **Fase Atual**: IntegraÃ§Ã£o completa e otimizaÃ§Ã£o

Hoje, Alexandria Ã© um sistema cognitivo completo que combina **7 paradigmas teÃ³ricos** em uma arquitetura unificada.

---

## ğŸ§  Como Funciona

### Arquitetura Completa

```mermaid
graph TB
    subgraph Input["ğŸ“¥ INTERFACE DE ENTRADA"]
        A[Documentos/Imagens]
        B[Queries do UsuÃ¡rio]
    end
    
    subgraph Processing["âš™ï¸ PROCESSAMENTO MULTIMODAL"]
        C[Sentence Transformer]
        D[V11 Vision Encoder]
        E[384D Embeddings]
    end
    
    subgraph Compression["ï¿½ï¸ COMPRESSÃƒO NEURAL"]
        F[VQ-VAE Monolith V13]
        G[Product Quantizer]
        H[4 bytes/chunk]
        I[4 heads Ã— 256 codes]
    end
    
    subgraph Memory["ğŸ—„ï¸ MEMÃ“RIA SEMÃ‚NTICA"]
        J[LanceDB Vector Store]
        K[193k documents indexed]
    end
    
    subgraph Reasoning["ğŸ„ RACIOCÃNIO MICELAR"]
        L[Mycelial Network]
        M[638k Hebbian Connections]
        N[Activation Propagation]
    end
    
    subgraph Nemesis["ğŸ§¬ NEMESIS CORE"]
        O[Active Inference Agents]
        P[Predictive Coding]
        Q[Free Energy Minimization]
    end
    
    subgraph Intelligence["ğŸ¯ CAMADA DE INTELIGÃŠNCIA"]
        R[Abduction Engine]
        S[Causal Reasoning]
        T[Meta-Hebbian Plasticity]
    end
    
    subgraph Output["ğŸ“¤ SAÃDA"]
        U[Respostas Enriquecidas]
        V[HipÃ³teses Geradas]
        W[AÃ§Ãµes AutÃ´nomas]
    end
    
    A --> C
    A --> D
    B --> J
    C --> E
    D --> E
    E --> F
    F --> G
    G --> H
    H --> I
    I --> J
    J --> L
    L --> M
    M --> N
    N --> O
    O --> P
    P --> Q
    Q --> R
    R --> S
    S --> T
    T --> U
    T --> V
    T --> W
    
    style Input fill:#e3f2fd
    style Processing fill:#fff3e0
    style Compression fill:#f3e5f5
    style Memory fill:#e8f5e9
    style Reasoning fill:#fce4ec
    style Nemesis fill:#fff9c4
    style Intelligence fill:#e0f2f1
    style Output fill:#fce4ec
```

### Fluxo de Dados

```
1. INGESTÃƒO
   â””â”€> Document â†’ Chunking (~1000 chars) â†’ Embedding (384D)

2. COMPRESSÃƒO
   â””â”€> Embedding â†’ VQ-VAE â†’ 4 bytes (96% compression)

3. ARMAZENAMENTO
   â””â”€> LanceDB indexing + Mycelial observation

4. RACIOCÃNIO
   â”œâ”€> Semantic Search (LanceDB)
   â”œâ”€> Hebbian Propagation (Mycelial)
   â””â”€> Active Inference (Nemesis)

5. SÃNTESE
   â”œâ”€> Abduction (Gap detection)
   â”œâ”€> Causal Reasoning (Graph construction)
   â””â”€> Meta-Hebbian Plasticity (Self-optimization)

6. AÃ‡ÃƒO
   â””â”€> Response | Hypothesis | Autonomous Action
```

---

## ï¿½ Fundamentos TeÃ³ricos

Alexandria combina mÃºltiplas teorias de neurociÃªncia computacional e IA:

### 1. **Hebbian Learning** (Donald Hebb, 1949)
> *"Neurons that fire together, wire together"*

- **AplicaÃ§Ã£o**: Mycelial Network aprende co-ocorrÃªncias de cÃ³digos VQ-VAE
- **Vantagem**: NÃ£o-supervisionado, online, biologicamente plausÃ­vel
- **Status**: 638,130 conexÃµes ativas, densidade <1%

### 2. **Free Energy Principle** (Karl Friston, 2010)
> Sistemas inteligentes minimizam surpresa variacional

- **AplicaÃ§Ã£o**: Nemesis Core usa Active Inference para seleÃ§Ã£o de aÃ§Ãµes
- **Vantagem**: Framework unificado para percepÃ§Ã£o, aÃ§Ã£o e aprendizado
- **Status**: Operacional com overflow warnings esperados

### 3. **Predictive Coding** (Rao & Ballard, 1999)
> CÃ©rebros sÃ£o mÃ¡quinas preditivas que minimizam erro

- **AplicaÃ§Ã£o**: Hierarquia de 5 camadas prediz embeddings
- **Vantagem**: CompressÃ£o + prediÃ§Ã£o em uma Ãºnica arquitetura
- **Status**: 4 camadas construÃ­das (384â†’256â†’128â†’64â†’32)

### 4. **Vector Quantization** (VQ-VAE, van den Oord, 2017)
> CompressÃ£o neural via codebook discreto

- **AplicaÃ§Ã£o**: Monolith V13 com 4 heads Ã— 256 codes
- **Vantagem**: 96% compression mantendo reconstruÃ§Ã£o (MSE 0.0021)
- **Status**: 255/256 cÃ³digos ativos, Head 0 dominante (67%)

### 5. **Abductive Reasoning** (Charles Peirce, 1878)
> InferÃªncia Ã  melhor explicaÃ§Ã£o

- **AplicaÃ§Ã£o**: DetecÃ§Ã£o automÃ¡tica de gaps e geraÃ§Ã£o de hipÃ³teses
- **Vantagem**: ExpansÃ£o autÃ´noma de conhecimento
- **Status**: Gap detection operacional

### 6. **Meta-Learning** (Schmidhuber, 1987)
> Aprender a aprender

- **AplicaÃ§Ã£o**: Meta-Hebbian ajusta taxas de plasticidade dinamicamente
- **Vantagem**: Auto-otimizaÃ§Ã£o sem intervenÃ§Ã£o manual
- **Status**: Implementado, em teste

---

## ğŸ—ï¸ MÃ³dulos Principais

### Pre-Structural Field (Geometric Cognition) ğŸ†•
**Arquivos**: `core/field/`

- **DynamicManifold**: Variedade com dimensÃ£o variÃ¡vel (384â†’416D)
- **RiemannianMetric**: MÃ©trica que deforma com ativaÃ§Ã£o
- **FreeEnergyField**: Campo F(x) = E - TÂ·S
- **CycleDynamics**: ExpansÃ£oâ†’ConfiguraÃ§Ã£oâ†’CompressÃ£o
- **Status**: âœ… Operacional (testado com 352k docs)

### VQ-VAE (Neural Compression)
**Arquivo**: `core/reasoning/vqvae/`

- **Monolith V13**: 4 heads, 256 codes/head, 384D â†’ 4 bytes
- **Head Balance Regularization**: Previne colapso de codebook
- **Status**: âœ… ProduÃ§Ã£o (epoch 20, codebook 99.6% ativo)

### Mycelial Network (Hebbian Reasoning)
**Arquivo**: `core/reasoning/mycelial_reasoning.py`

- **638,130 conexÃµes** aprendidas via Hebb
- **PropagaÃ§Ã£o**: 3-5 steps para enriquecer queries
- **Status**: âœ… SaudÃ¡vel (densidade <1%, hubs emergentes)

### Nemesis Core (Active Inference)
**Arquivos**: `core/learning/`

- **Active Inference**: Scout, Judge, Weaver agents
- **Predictive Coding**: 5-layer hierarchical prediction
- **Free Energy**: GovernanÃ§a top-level
- **Status**: âœ… Operacional (warnings numÃ©ricos esperados)

### LanceDB (Vector Storage)
**Arquivo**: `core/memory/storage.py`

- **352,000+ documentos** indexados
- **Busca**: <50ms (p99) para top-10
- **Status**: âœ… Operacional

---

## ğŸ“Š MÃ©tricas de Performance

| OperaÃ§Ã£o | Performance | Notas |
|:---|:---:|:---|
| **IndexaÃ§Ã£o** | 1,000 chunks/s | Batch processing |
| **Busca Vetorial** | <50ms (p99) | Top-10 resultados |
| **PropagaÃ§Ã£o Micelar** | <15ms | 3 steps |
| **CompressÃ£o VQ-VAE** | 96% | 384D â†’ 4 bytes |
| **Codebook Ativo** | 99.6% | 255/256 codes |
| **ConexÃµes Hebbian** | 638,130 | Densidade <1% |

### Escalabilidade

| Documentos | RAM | Query Latency |
|:---:|:---:|:---:|
| 10K | 30 MB | 50ms |
| 100K | 295 MB | 80ms |
| 1M | 2.8 GB | 150ms |

---

## ğŸ“š DocumentaÃ§Ã£o

A documentaÃ§Ã£o estÃ¡ organizada topologicamente em [`docs/`](docs/):

```
docs/
â”œâ”€â”€ README.md                    # ğŸ¯ Ãndice principal (COMECE AQUI)
â”‚
â”œâ”€â”€ architecture/                # ğŸ—ï¸ Arquitetura do Sistema
â”‚   â”œâ”€â”€ overview.md             #    â†’ Diagramas visuais e fluxo
â”‚   â”œâ”€â”€ technical.md            #    â†’ AnÃ¡lise tÃ©cnica completa
â”‚   â””â”€â”€ components.md           #    â†’ Breakdown de mÃ³dulos
â”‚
â”œâ”€â”€ modules/                     # ğŸ“¦ DocumentaÃ§Ã£o TÃ©cnica
â”‚   â”œâ”€â”€ README.md               #    â†’ Ãndice navegÃ¡vel
â”‚   â”œâ”€â”€ 01-09_*.md              #    â†’ MÃ³dulos core
â”‚   â””â”€â”€ NEMESIS_MANUAL.md       #    â†’ Bio-inspired learning
â”‚
â”œâ”€â”€ guides/                      # ğŸ“˜ Guias de Uso
â”‚   â””â”€â”€ user-manual.md          #    â†’ Manual do usuÃ¡rio
â”‚
â”œâ”€â”€ reports/                     # ğŸ§ª AnÃ¡lises e Experimentos
â””â”€â”€ concepts/                    # ğŸ’¡ Conceitos AvanÃ§ados
```

### ğŸ“ **Comece Aqui por Perfil**

| Perfil | Documento Recomendado |
|--------|----------------------|
| **ğŸŸ¢ Iniciante** | [`docs/architecture/overview.md`](docs/architecture/overview.md) |
| **ğŸŸ¡ Desenvolvedor** | [`docs/architecture/technical.md`](docs/architecture/technical.md) |
| **ğŸ”´ Pesquisador** | [`docs/architecture/components.md`](docs/architecture/components.md) |
| **ğŸ“– UsuÃ¡rio Final** | [`docs/guides/user-manual.md`](docs/guides/user-manual.md) |
| **âš™ï¸ MÃ³dulo EspecÃ­fico** | [`docs/modules/README.md`](docs/modules/README.md) |

### ğŸ“Š **DocumentaÃ§Ã£o por Tipo**

- **Visual & Diagramas**: [`docs/architecture/overview.md`](docs/architecture/overview.md)
- **TÃ©cnica & CÃ³digo**: [`docs/architecture/technical.md`](docs/architecture/technical.md)
- **AnÃ¡lise de MÃ³dulos**: [`docs/architecture/components.md`](docs/architecture/components.md)
- **Guias de Uso**: [`docs/guides/`](docs/guides/)
- **Experimentos**: [`docs/reports/`](docs/reports/)

**RelatÃ³rios TÃ©cnicos** (auto-gerados):
- VQ-VAE Deep Analysis
- Experimental Ablation Suite (A-D)
- Module Integration Status
- Cleanup Reports

---

## ï¿½ Quick Start

```bash
# Clone
git clone https://github.com/GAndreuu/Prototype-Alexandria.git
cd Alexandria

# Setup
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt

# Initialize
python scripts/init_brain.py

# Index documents
from core.memory.semantic_memory import SemanticFileSystem
from core.topology.topology_engine import TopologyEngine

engine = TopologyEngine()
memory = SemanticFileSystem(engine)
memory.index_file("path/to/document.pdf")

# Query
results = memory.retrieve("quantum computing", limit=10)
```

**Interface**:
```bash
streamlit run interface/app.py
# Access: http://localhost:8501
```

---

## ï¿½ï¸ Roadmap

### âœ… Fase Atual: Production Ready
- [x] VQ-VAE compression & balance
- [x] Mycelial reasoning network
- [x] Nemesis Core integration
- [x] Complete system verification

### ğŸ”„ PrÃ³xima Fase: Enhanced Intelligence
- [ ] Chain-of-Thought integration
- [ ] Local LLM integration (Llama 3)
- [ ] Tool use framework
- [ ] Self-reflection loops

### ğŸŒŸ Fase Futura: Meta-Learning
- [ ] Performance tracking dashboard
- [ ] Automated hyperparameter search
- [ ] Curriculum generation
- [ ] Multi-task learning

---

## ğŸ¤ Contribuindo

Alexandria Ã© open-source e aceita contribuiÃ§Ãµes! Veja [CONTRIBUTING.md](CONTRIBUTING.md).

---

## ï¿½ LicenÃ§a

MIT License - Veja [LICENSE](LICENSE) para detalhes.

---

<div align="center">

**Alexandria Cognitive System**

*Building local AGI, one commit at a time*

â­ Star se Alexandria ajudou sua pesquisa!

**Contato**: [gabrielandreu82@hotmail.com](mailto:gabrielandreu82@hotmail.com)

</div>
