"""
Free Energy Principle - Alexandria
===================================

ImplementaÃ§Ã£o completa do PrincÃ­pio de Energia Livre para o sistema Alexandria.
Este Ã© o topo da hierarquia conceitual que unifica todos os mÃ³dulos anteriores.

O PrincÃ­pio de Energia Livre (Friston, 2010) afirma que sistemas auto-organizados
resistem Ã  entropia minimizando uma quantidade chamada "energia livre variacional".

                            FREE ENERGY PRINCIPLE
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚               â”‚               â”‚
                    â–¼               â–¼               â–¼
              PERCEPÃ‡ÃƒO          AÃ‡ÃƒO          APRENDIZADO
             (Predictive     (Active        (Meta-Hebbian)
              Coding)        Inference)
                    â”‚               â”‚               â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
                         MINIMIZAÃ‡ÃƒO DE F
                    F = E_Q[log Q(s) - log P(o,s)]
                    F = Complexity - Accuracy
                    F = Energy - Entropy


Hierarquia completa:
    âœ… Hebbian (base) - minimiza energia local
    âœ… Meta-Hebbian - aprende como minimizar
    âœ… Predictive Coding - minimiza erro de prediÃ§Ã£o
    âœ… Active Inference - minimiza F esperado via aÃ§Ã£o
    âœ… Free Energy - princÃ­pio unificador (ESTE ARQUIVO)


Este mÃ³dulo implementa:
1. Variational Free Energy (VFE) - mÃ©trica central
2. Expected Free Energy (EFE) - para seleÃ§Ã£o de aÃ§Ã£o
3. Orquestrador que coordena todos os mÃ³dulos
4. Self-tuning baseado em gradientes de F
5. Monitoramento de "saÃºde" do sistema

ReferÃªncias:
- Friston (2010) - The free-energy principle: a unified brain theory?
- Friston (2019) - A free energy principle for a particular physics
- Parr, Pezzulo & Friston (2022) - Active Inference: The Free Energy Principle in Mind, Brain, and Behavior

Autor: G (Alexandria Project)
VersÃ£o: 1.0
"""

import numpy as np
from typing import Dict, Any, Optional, List, Tuple, Callable, Union
from dataclasses import dataclass, field
from enum import Enum, auto
from pathlib import Path
import pickle
import time
from collections import deque

# =============================================================================
# IMPORTS DOS MÃ“DULOS
# =============================================================================

try:
    from meta_hebbian import MetaHebbianPlasticity, create_meta_hebbian_system
    HAS_META_HEBBIAN = True
except ImportError:
    HAS_META_HEBBIAN = False

try:
    from predictive_coding import PredictiveCodingNetwork, create_predictive_coding_system
    HAS_PREDICTIVE_CODING = True
except ImportError:
    HAS_PREDICTIVE_CODING = False

try:
    from active_inference import (
        ActiveInferenceAgent, 
        ActiveInferenceAlexandria,
        create_active_inference_system,
        Action,
        ActionType
    )
    HAS_ACTIVE_INFERENCE = True
except ImportError:
    HAS_ACTIVE_INFERENCE = False

try:
    from integration_layer import (
        AlexandriaIntegratedPipeline,
        create_integrated_pipeline,
        SparseGraphAdapter
    )
    HAS_INTEGRATION = True
except ImportError:
    HAS_INTEGRATION = False


# =============================================================================
# TEORIA: DECOMPOSIÃ‡ÃƒO DA FREE ENERGY
# =============================================================================

"""
VARIATIONAL FREE ENERGY (VFE):
==============================

    F = E_Q[log Q(s) - log P(o,s)]

Onde:
- Q(s) = distribuiÃ§Ã£o aproximada sobre estados (beliefs)
- P(o,s) = modelo generativo (likelihood Ã— prior)
- o = observaÃ§Ãµes
- s = estados latentes

DecomposiÃ§Ã£o 1 (Complexity - Accuracy):
    F = D_KL[Q(s) || P(s)] - E_Q[log P(o|s)]
        \_____________/     \______________/
          Complexity           Accuracy
    
    Complexity: quÃ£o distante Q estÃ¡ do prior P(s)
    Accuracy: quÃ£o bem o modelo explica as observaÃ§Ãµes

DecomposiÃ§Ã£o 2 (Energy - Entropy):
    F = E_Q[-log P(o,s)] - H[Q(s)]
        \_____________/   \_____/
           Energy         Entropy
    
    Energy: "custo" das observaÃ§Ãµes sob o modelo
    Entropy: incerteza dos beliefs

Para MINIMIZAR F, o sistema pode:
1. PERCEPÃ‡ÃƒO: Atualizar Q(s) para explicar melhor P(o|s)
2. AÃ‡ÃƒO: Mudar o mundo para que o seja mais provÃ¡vel sob P
3. APRENDIZADO: Modificar P para que se ajuste melhor a o

Isso unifica:
- Predictive Coding â†’ minimiza F via percepÃ§Ã£o
- Active Inference â†’ minimiza E[F] via aÃ§Ã£o
- Meta-Hebbian â†’ otimiza parÃ¢metros de P


EXPECTED FREE ENERGY (EFE):
===========================

    G(Ï€) = E_Q[F] sob policy Ï€

DecompÃµe em:
    G(Ï€) = Risk + Ambiguity
    
    Risk = D_KL[Q(o|Ï€) || P(o)]  (divergÃªncia de preferÃªncias)
    Ambiguity = E_Q[H(o|s,Ï€)]    (incerteza epistÃªmica)

Active Inference seleciona aÃ§Ãµes que minimizam G.
"""


# =============================================================================
# CONFIGURAÃ‡ÃƒO
# =============================================================================

class FreeEnergyMode(Enum):
    """Modos de operaÃ§Ã£o do sistema"""
    PERCEPTION = auto()      # SÃ³ atualiza beliefs
    ACTION = auto()          # Atua no mundo
    LEARNING = auto()        # Atualiza modelo
    FULL = auto()            # Todos simultaneamente


@dataclass
class FreeEnergyConfig:
    """ConfiguraÃ§Ã£o do sistema de Free Energy"""
    
    # DimensÃµes
    state_dim: int = 64              # DimensÃ£o do espaÃ§o de estados
    observation_dim: int = 384       # DimensÃ£o das observaÃ§Ãµes (embeddings)
    
    # Pesos dos componentes de F
    complexity_weight: float = 1.0   # Peso do termo de complexidade
    accuracy_weight: float = 1.0     # Peso do termo de acurÃ¡cia
    
    # Pesos para EFE
    risk_weight: float = 1.0
    ambiguity_weight: float = 1.0
    novelty_weight: float = 0.3      # Bonus para exploraÃ§Ã£o
    
    # DinÃ¢mica
    belief_learning_rate: float = 0.1
    model_learning_rate: float = 0.01
    precision_learning_rate: float = 0.001
    
    # Prior preferences (estados desejados)
    preferred_states: Optional[np.ndarray] = None
    
    # HistÃ³rico
    history_length: int = 1000
    
    # PersistÃªncia
    save_path: str = "data/free_energy_state.pkl"


# =============================================================================
# VARIATIONAL FREE ENERGY
# =============================================================================

class VariationalFreeEnergy:
    """
    ImplementaÃ§Ã£o da Energia Livre Variacional.
    
    Esta Ã© a mÃ©trica central que todos os mÃ³dulos trabalham para minimizar.
    
    F = Complexity - Accuracy
    F = D_KL[Q(s) || P(s)] - E_Q[log P(o|s)]
    """
    
    def __init__(self, config: FreeEnergyConfig):
        self.config = config
        
        # Beliefs Q(s): parametrizado como Gaussiana
        self.belief_mean = np.zeros(config.state_dim)
        self.belief_precision = np.ones(config.state_dim)  # 1/variance
        
        # Prior P(s): tambÃ©m Gaussiana
        self.prior_mean = np.zeros(config.state_dim)
        self.prior_precision = np.ones(config.state_dim) * 0.1  # Prior vago
        
        # Likelihood P(o|s): modelo linear + ruÃ­do
        # Mapeia state_dim â†’ observation_dim
        self.likelihood_matrix = np.random.randn(
            config.observation_dim, config.state_dim
        ) * 0.1
        self.likelihood_precision = np.ones(config.observation_dim)
        
        # Matriz de projeÃ§Ã£o inversa (observation â†’ state) para inferÃªncia
        self.recognition_matrix = np.random.randn(
            config.state_dim, config.observation_dim
        ) * 0.1
        
        # PreferÃªncias P(o): estados de observaÃ§Ã£o preferidos
        if config.preferred_states is not None:
            self.preferred_observations = config.preferred_states
        else:
            self.preferred_observations = np.zeros(config.observation_dim)
        
        # HistÃ³rico
        self.F_history: deque = deque(maxlen=config.history_length)
        self.complexity_history: deque = deque(maxlen=config.history_length)
        self.accuracy_history: deque = deque(maxlen=config.history_length)
        
    def compute(
        self,
        observation: Optional[np.ndarray] = None
    ) -> Tuple[float, Dict[str, float]]:
        """
        Computa Variational Free Energy.
        
        F = Complexity - Accuracy
        
        Returns:
            F: Energia livre total
            components: Breakdown dos termos
        """
        # === COMPLEXITY ===
        # D_KL[Q(s) || P(s)] para Gaussianas
        complexity = self._kl_divergence_gaussian(
            self.belief_mean, 1.0 / self.belief_precision,
            self.prior_mean, 1.0 / self.prior_precision
        )
        
        # === ACCURACY ===
        # E_Q[log P(o|s)]
        obs_error = np.zeros(self.config.state_dim)  # Default
        if observation is not None:
            # Projeta observaÃ§Ã£o para espaÃ§o de estados para comparaÃ§Ã£o
            if len(observation) != self.config.state_dim:
                # Usa recognition model para projetar
                projected_obs = self.recognition_matrix @ observation
            else:
                projected_obs = observation
            
            # Erro no espaÃ§o de estados
            obs_error = projected_obs - self.belief_mean
            
            # Log-likelihood (Gaussiana)
            accuracy = -0.5 * np.sum(
                self.belief_precision * obs_error**2
            )
            accuracy += 0.5 * np.sum(np.log(self.belief_precision + 1e-10))
        else:
            accuracy = 0.0
        
        # === FREE ENERGY ===
        F = (
            self.config.complexity_weight * complexity -
            self.config.accuracy_weight * accuracy
        )
        
        # HistÃ³rico
        self.F_history.append(F)
        self.complexity_history.append(complexity)
        self.accuracy_history.append(accuracy)
        
        return F, {
            'complexity': complexity,
            'accuracy': accuracy,
            'F': F,
            'belief_entropy': self._entropy_gaussian(1.0 / self.belief_precision),
            'prediction_error': float(np.mean(obs_error**2)) if observation is not None else 0
        }
    
    def update_beliefs(
        self,
        observation: np.ndarray,
        learning_rate: Optional[float] = None
    ) -> Dict[str, Any]:
        """
        Atualiza beliefs Q(s) para minimizar F.
        
        Isso Ã© equivalente ao que Predictive Coding faz:
        move os beliefs na direÃ§Ã£o que reduz erro de prediÃ§Ã£o.
        """
        lr = learning_rate or self.config.belief_learning_rate
        
        # Projeta observaÃ§Ã£o para espaÃ§o de estados
        if len(observation) != self.config.state_dim:
            projected_obs = self.recognition_matrix @ observation
        else:
            projected_obs = observation
        
        # Erro de prediÃ§Ã£o no espaÃ§o de estados
        prediction_error = projected_obs - self.belief_mean
        
        # Gradiente do termo de complexidade
        grad_complexity = self.belief_precision * (self.belief_mean - self.prior_mean)
        
        # Gradiente do termo de acurÃ¡cia
        grad_accuracy = self.belief_precision * prediction_error
        
        # Gradiente total de F
        grad_F = grad_complexity - grad_accuracy
        
        # AtualizaÃ§Ã£o (gradient descent em F)
        self.belief_mean -= lr * grad_F
        
        # TambÃ©m atualiza precisÃ£o dos beliefs (incerteza)
        error_magnitude = np.mean(prediction_error**2)
        precision_update = self.config.precision_learning_rate * (
            1.0 / (error_magnitude + 0.01) - np.mean(self.belief_precision)
        )
        self.belief_precision += precision_update
        self.belief_precision = np.clip(self.belief_precision, 0.1, 100.0)
        
        # Computa F apÃ³s atualizaÃ§Ã£o
        F_new, components = self.compute(observation)
        
        return {
            'F_before': self.F_history[-2] if len(self.F_history) > 1 else float('inf'),
            'F_after': F_new,
            'F_reduction': (self.F_history[-2] - F_new) if len(self.F_history) > 1 else 0,
            'prediction_error': float(np.mean(prediction_error**2)),
            'gradient_norm': float(np.linalg.norm(grad_F)),
            'components': components
        }
    
    def update_model(
        self,
        observation: np.ndarray,
        learning_rate: Optional[float] = None
    ) -> Dict[str, Any]:
        """
        Atualiza modelo generativo (recognition matrix) para minimizar F.
        
        Isso Ã© o APRENDIZADO: melhora a projeÃ§Ã£o observation â†’ state.
        """
        lr = learning_rate or self.config.model_learning_rate
        
        # Projeta observaÃ§Ã£o
        if len(observation) != self.config.state_dim:
            projected_obs = self.recognition_matrix @ observation
        else:
            projected_obs = observation
        
        # Erro
        prediction_error = projected_obs - self.belief_mean
        
        # Gradiente para recognition matrix
        if len(observation) != self.config.state_dim:
            grad_R = np.outer(prediction_error, observation)
            self.recognition_matrix -= lr * grad_R
        
        return {
            'model_change': float(np.mean(np.abs(prediction_error))),
            'belief_norm': float(np.linalg.norm(self.belief_mean))
        }
    
    def _kl_divergence_gaussian(
        self,
        mu1: np.ndarray, var1: np.ndarray,
        mu2: np.ndarray, var2: np.ndarray
    ) -> float:
        """KL divergence entre duas Gaussianas diagonais"""
        k = len(mu1)
        
        # D_KL = 0.5 * (tr(Î£2^-1 @ Î£1) + (Î¼2-Î¼1).T @ Î£2^-1 @ (Î¼2-Î¼1) - k + log(det(Î£2)/det(Î£1)))
        var1 = np.maximum(var1, 1e-10)
        var2 = np.maximum(var2, 1e-10)
        
        trace_term = np.sum(var1 / var2)
        mean_term = np.sum((mu2 - mu1)**2 / var2)
        log_det_term = np.sum(np.log(var2)) - np.sum(np.log(var1))
        
        kl = 0.5 * (trace_term + mean_term - k + log_det_term)
        return max(0, kl)  # KL Ã© sempre >= 0
    
    def _entropy_gaussian(self, variance: np.ndarray) -> float:
        """Entropia de Gaussiana diagonal"""
        k = len(variance)
        return 0.5 * k * (1 + np.log(2 * np.pi)) + 0.5 * np.sum(np.log(variance + 1e-10))
    
    def get_belief_state(self) -> Dict[str, np.ndarray]:
        """Retorna estado atual dos beliefs"""
        return {
            'mean': self.belief_mean.copy(),
            'precision': self.belief_precision.copy(),
            'variance': 1.0 / self.belief_precision
        }
    
    def get_surprise(self, observation: np.ndarray) -> float:
        """
        Computa "surpresa" de uma observaÃ§Ã£o.
        
        Surprise = -log P(o) â‰ˆ F (sob certas condiÃ§Ãµes)
        """
        F, _ = self.compute(observation)
        return F


# =============================================================================
# EXPECTED FREE ENERGY (para seleÃ§Ã£o de aÃ§Ã£o)
# =============================================================================

class ExpectedFreeEnergy:
    """
    Expected Free Energy para seleÃ§Ã£o de aÃ§Ãµes.
    
    G(Ï€) = Risk + Ambiguity
         = D_KL[Q(o|Ï€) || P(o)] + E_Q[H(o|s,Ï€)]
    
    Risk: quÃ£o longe das preferÃªncias a aÃ§Ã£o nos leva
    Ambiguity: quanta incerteza sobre outcomes
    """
    
    def __init__(
        self,
        vfe: VariationalFreeEnergy,
        config: FreeEnergyConfig
    ):
        self.vfe = vfe
        self.config = config
        
        # Modelos de transiÃ§Ã£o por tipo de aÃ§Ã£o
        self.transition_models: Dict[str, np.ndarray] = {}
        self._init_transition_models()
        
    def _init_transition_models(self):
        """Inicializa modelos de transiÃ§Ã£o simplificados"""
        dim = self.config.state_dim
        
        # AÃ§Ãµes bÃ¡sicas (pode ser expandido)
        actions = ['explore', 'exploit', 'query', 'consolidate', 'rest']
        
        for action in actions:
            # Matriz de transiÃ§Ã£o inicial
            if action == 'explore':
                # ExploraÃ§Ã£o aumenta variÃ¢ncia
                T = np.eye(dim) * 0.8 + np.random.randn(dim, dim) * 0.2
            elif action == 'exploit':
                # ExploitaÃ§Ã£o Ã© mais determinÃ­stica
                T = np.eye(dim) * 0.95 + np.random.randn(dim, dim) * 0.05
            elif action == 'consolidate':
                # ConsolidaÃ§Ã£o move em direÃ§Ã£o ao prior
                T = np.eye(dim) * 0.9
            else:
                # Default
                T = np.eye(dim) * 0.85 + np.random.randn(dim, dim) * 0.1
            
            self.transition_models[action] = T
    
    def compute(
        self,
        action: str,
        current_state: Optional[np.ndarray] = None
    ) -> Tuple[float, Dict[str, float]]:
        """
        Computa Expected Free Energy para uma aÃ§Ã£o.
        
        Returns:
            G: Expected Free Energy (menor Ã© melhor)
            components: Breakdown
        """
        state = current_state if current_state is not None else self.vfe.belief_mean
        
        # Prediz prÃ³ximo estado
        T = self.transition_models.get(action, np.eye(len(state)))
        predicted_state = T @ state
        
        # Prediz observaÃ§Ã£o
        predicted_obs = self.vfe.likelihood_matrix @ predicted_state
        
        # === RISK ===
        # DivergÃªncia das preferÃªncias
        risk = np.sum((predicted_obs - self.vfe.preferred_observations)**2)
        risk *= self.config.risk_weight
        
        # === AMBIGUITY ===
        # Incerteza sobre outcomes (simplificado)
        # Em modelo completo, seria H(o|s,Ï€)
        state_uncertainty = 1.0 / np.mean(self.vfe.belief_precision)
        ambiguity = state_uncertainty * self.config.ambiguity_weight
        
        # === NOVELTY BONUS ===
        novelty = 0.0
        if action == 'explore':
            novelty = -self.config.novelty_weight  # Bonus negativo (reduz G)
        
        # === EFE TOTAL ===
        G = risk + ambiguity + novelty
        
        return G, {
            'risk': risk,
            'ambiguity': ambiguity,
            'novelty': novelty,
            'G': G
        }
    
    def select_action(
        self,
        available_actions: Optional[List[str]] = None,
        temperature: float = 1.0
    ) -> Tuple[str, Dict[str, Any]]:
        """
        Seleciona aÃ§Ã£o que minimiza G.
        
        Usa softmax para exploraÃ§Ã£o.
        """
        actions = available_actions or list(self.transition_models.keys())
        
        # Computa G para cada aÃ§Ã£o
        Gs = []
        components_list = []
        for action in actions:
            G, components = self.compute(action)
            Gs.append(G)
            components_list.append(components)
        
        Gs = np.array(Gs)
        
        # Softmax selection (menor G = maior probabilidade)
        Gs_normalized = Gs - np.min(Gs)
        probs = np.exp(-Gs_normalized / temperature)
        probs = probs / np.sum(probs)
        
        # Seleciona
        selected_idx = np.random.choice(len(actions), p=probs)
        selected_action = actions[selected_idx]
        
        return selected_action, {
            'all_actions': list(zip(actions, Gs.tolist())),
            'selected_G': Gs[selected_idx],
            'selection_prob': probs[selected_idx],
            'components': components_list[selected_idx]
        }


# =============================================================================
# ORQUESTRADOR FREE ENERGY
# =============================================================================

class FreeEnergyOrchestrator:
    """
    Orquestrador central que coordena todos os mÃ³dulos sob o PrincÃ­pio de Free Energy.
    
    Este Ã© o "cÃ©rebro central" que:
    1. Monitora F global do sistema
    2. Decide quando fazer percepÃ§Ã£o, aÃ§Ã£o ou aprendizado
    3. Balanceia exploration vs exploitation
    4. MantÃ©m o sistema em regime de baixa energia livre
    """
    
    def __init__(
        self,
        config: Optional[FreeEnergyConfig] = None,
        pipeline: Optional['AlexandriaIntegratedPipeline'] = None
    ):
        self.config = config or FreeEnergyConfig()
        self.pipeline = pipeline
        
        # Componentes core
        self.vfe = VariationalFreeEnergy(self.config)
        self.efe = ExpectedFreeEnergy(self.vfe, self.config)
        
        # Estado
        self.mode = FreeEnergyMode.FULL
        self.timestep = 0
        self.last_F = float('inf')
        
        # EstatÃ­sticas
        self.action_counts: Dict[str, int] = {}
        self.mode_history: List[FreeEnergyMode] = []
        
        # Thresholds adaptativos
        self.F_threshold_perception = 10.0  # Quando F > threshold, foca em percepÃ§Ã£o
        self.F_threshold_action = 5.0       # Quando F moderado, pode agir
        self.F_target = 1.0                 # F alvo (nunca chega a zero)
        
    def step(
        self,
        observation: Optional[np.ndarray] = None,
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Executa um passo do ciclo de Free Energy.
        
        1. Computa F atual
        2. Decide modo (percepÃ§Ã£o/aÃ§Ã£o/aprendizado)
        3. Executa operaÃ§Ã£o
        4. Atualiza estado
        
        Returns:
            result: Resultado do passo
        """
        result = {
            'timestep': self.timestep,
            'mode': None,
            'F_before': None,
            'F_after': None,
            'action_taken': None
        }
        
        # 1. Computa F inicial
        F_before, components = self.vfe.compute(observation)
        result['F_before'] = F_before
        result['components'] = components
        
        # 2. Decide modo baseado em F
        mode = self._select_mode(F_before, observation is not None)
        result['mode'] = mode.name
        self.mode_history.append(mode)
        
        # 3. Executa operaÃ§Ã£o correspondente
        if mode == FreeEnergyMode.PERCEPTION and observation is not None:
            # Atualiza beliefs para explicar observaÃ§Ã£o
            update_result = self.vfe.update_beliefs(observation)
            result['perception'] = update_result
            
        elif mode == FreeEnergyMode.LEARNING and observation is not None:
            # Atualiza modelo generativo
            update_result = self.vfe.update_beliefs(observation)
            model_result = self.vfe.update_model(observation)
            result['learning'] = {**update_result, **model_result}
            
        elif mode == FreeEnergyMode.ACTION:
            # Seleciona e "executa" aÃ§Ã£o
            action, action_info = self.efe.select_action()
            result['action_taken'] = action
            result['action_info'] = action_info
            
            # Registra
            self.action_counts[action] = self.action_counts.get(action, 0) + 1
            
            # Simula efeito da aÃ§Ã£o no estado
            T = self.efe.transition_models.get(action, np.eye(self.config.state_dim))
            self.vfe.belief_mean = T @ self.vfe.belief_mean
            
        elif mode == FreeEnergyMode.FULL and observation is not None:
            # Faz tudo
            update_result = self.vfe.update_beliefs(observation)
            model_result = self.vfe.update_model(observation)
            action, action_info = self.efe.select_action()
            
            result['perception'] = update_result
            result['learning'] = model_result
            result['action_taken'] = action
            result['action_info'] = action_info
        
        # 4. Computa F final
        F_after, _ = self.vfe.compute(observation)
        result['F_after'] = F_after
        result['F_reduction'] = F_before - F_after
        
        # Atualiza estado
        self.last_F = F_after
        self.timestep += 1
        
        # Adapta thresholds
        self._adapt_thresholds()
        
        return result
    
    def _select_mode(self, F: float, has_observation: bool) -> FreeEnergyMode:
        """
        Seleciona modo de operaÃ§Ã£o baseado em F.
        
        - F muito alto â†’ foca em percepÃ§Ã£o (entender o que estÃ¡ acontecendo)
        - F moderado â†’ pode agir (mudar o mundo)
        - F baixo â†’ aprendizado (refinar modelo)
        """
        if not has_observation:
            return FreeEnergyMode.ACTION
        
        if F > self.F_threshold_perception:
            return FreeEnergyMode.PERCEPTION
        elif F > self.F_threshold_action:
            # Alterna entre aÃ§Ã£o e percepÃ§Ã£o
            if self.timestep % 3 == 0:
                return FreeEnergyMode.ACTION
            else:
                return FreeEnergyMode.PERCEPTION
        else:
            # F baixo: pode fazer tudo ou focar em aprendizado
            if self.timestep % 5 == 0:
                return FreeEnergyMode.LEARNING
            else:
                return FreeEnergyMode.FULL
    
    def _adapt_thresholds(self):
        """Adapta thresholds baseado no histÃ³rico de F"""
        if len(self.vfe.F_history) < 10:
            return
        
        recent_F = list(self.vfe.F_history)[-50:]
        mean_F = np.mean(recent_F)
        std_F = np.std(recent_F)
        
        # Ajusta thresholds para serem relativos Ã  distribuiÃ§Ã£o de F
        self.F_threshold_perception = mean_F + std_F
        self.F_threshold_action = mean_F
        self.F_target = max(0.1, mean_F - std_F)
    
    def run(
        self,
        observations: List[np.ndarray],
        callback: Optional[Callable] = None
    ) -> List[Dict[str, Any]]:
        """
        Roda o orquestrador em uma sequÃªncia de observaÃ§Ãµes.
        """
        results = []
        
        for obs in observations:
            result = self.step(observation=obs)
            results.append(result)
            
            if callback:
                callback(result)
        
        return results
    
    def get_system_health(self) -> Dict[str, Any]:
        """
        Retorna "saÃºde" do sistema baseado em mÃ©tricas de Free Energy.
        """
        if len(self.vfe.F_history) == 0:
            return {'status': 'INITIALIZING', 'F': None}
        
        recent_F = list(self.vfe.F_history)[-100:]
        mean_F = np.mean(recent_F)
        std_F = np.std(recent_F)
        trend = np.polyfit(range(len(recent_F)), recent_F, 1)[0] if len(recent_F) > 1 else 0
        
        # DiagnÃ³stico
        if mean_F < self.F_target:
            status = "OPTIMAL"
            diagnosis = "Sistema em equilÃ­brio de baixa energia livre"
        elif mean_F < self.F_threshold_action:
            status = "HEALTHY"
            diagnosis = "Sistema funcionando bem, F moderado"
        elif mean_F < self.F_threshold_perception:
            status = "STRESSED"
            diagnosis = "F elevado, sistema precisa de mais percepÃ§Ã£o"
        else:
            status = "CRITICAL"
            diagnosis = "F muito alto, sistema em dificuldade"
        
        # Trend
        if trend < -0.01:
            trend_status = "IMPROVING"
        elif trend > 0.01:
            trend_status = "DEGRADING"
        else:
            trend_status = "STABLE"
        
        return {
            'status': status,
            'diagnosis': diagnosis,
            'F_current': self.last_F,
            'F_mean': mean_F,
            'F_std': std_F,
            'F_trend': trend_status,
            'timestep': self.timestep,
            'action_distribution': self.action_counts,
            'mode_recent': [m.name for m in self.mode_history[-10:]],
            'thresholds': {
                'perception': self.F_threshold_perception,
                'action': self.F_threshold_action,
                'target': self.F_target
            }
        }
    
    def get_state(self) -> Dict[str, Any]:
        """Retorna estado completo para persistÃªncia"""
        return {
            'timestep': self.timestep,
            'last_F': self.last_F,
            'belief_mean': self.vfe.belief_mean,
            'belief_precision': self.vfe.belief_precision,
            'prior_mean': self.vfe.prior_mean,
            'prior_precision': self.vfe.prior_precision,
            'likelihood_matrix': self.vfe.likelihood_matrix,
            'likelihood_precision': self.vfe.likelihood_precision,
            'recognition_matrix': self.vfe.recognition_matrix,
            'transition_models': self.efe.transition_models,
            'action_counts': self.action_counts,
            'F_history': list(self.vfe.F_history),
            'thresholds': {
                'perception': self.F_threshold_perception,
                'action': self.F_threshold_action,
                'target': self.F_target
            }
        }
    
    def save_state(self, path: Optional[str] = None) -> str:
        """Salva estado"""
        path = path or self.config.save_path
        Path(path).parent.mkdir(parents=True, exist_ok=True)
        
        with open(path, 'wb') as f:
            pickle.dump(self.get_state(), f)
        
        return path
    
    def load_state(self, path: Optional[str] = None) -> bool:
        """Carrega estado"""
        path = path or self.config.save_path
        
        if not Path(path).exists():
            return False
        
        try:
            with open(path, 'rb') as f:
                state = pickle.load(f)
            
            self.timestep = state['timestep']
            self.last_F = state['last_F']
            self.vfe.belief_mean = state['belief_mean']
            self.vfe.belief_precision = state['belief_precision']
            self.vfe.prior_mean = state['prior_mean']
            self.vfe.prior_precision = state['prior_precision']
            self.vfe.likelihood_matrix = state['likelihood_matrix']
            self.vfe.likelihood_precision = state['likelihood_precision']
            if 'recognition_matrix' in state:
                self.vfe.recognition_matrix = state['recognition_matrix']
            self.efe.transition_models = state['transition_models']
            self.action_counts = state.get('action_counts', {})
            
            thresholds = state.get('thresholds', {})
            self.F_threshold_perception = thresholds.get('perception', 10.0)
            self.F_threshold_action = thresholds.get('action', 5.0)
            self.F_target = thresholds.get('target', 1.0)
            
            return True
        except Exception as e:
            print(f"Erro ao carregar Free Energy: {e}")
            return False


# =============================================================================
# INTEGRAÃ‡ÃƒO COMPLETA COM ALEXANDRIA
# =============================================================================

class AlexandriaFreeEnergySystem:
    """
    Sistema completo de Free Energy para Alexandria.
    
    Integra:
    - FreeEnergyOrchestrator (este arquivo)
    - AlexandriaIntegratedPipeline (integration_layer.py)
    - Todos os mÃ³dulos anteriores
    
    Este Ã© o ponto de entrada unificado para o sistema cognitivo completo.
    """
    
    def __init__(
        self,
        config: Optional[FreeEnergyConfig] = None,
        embedding_model: Optional[Any] = None,
        vqvae: Optional[Any] = None,
        mycelial: Optional[Any] = None
    ):
        self.config = config or FreeEnergyConfig()
        
        # Cria pipeline integrado
        self.pipeline = None
        if HAS_INTEGRATION:
            self.pipeline = create_integrated_pipeline(
                embedding_model=embedding_model,
                vqvae=vqvae,
                mycelial=mycelial,
                load_existing=True
            )
        
        # Cria orquestrador
        self.orchestrator = FreeEnergyOrchestrator(self.config, self.pipeline)
        
        # Estado
        self.total_observations = 0
        
        print("ğŸ§  Alexandria Free Energy System inicializado")
        print(f"   DimensÃµes: state={self.config.state_dim}, obs={self.config.observation_dim}")
        
    def process(
        self,
        input_data: Union[str, np.ndarray],
        learn: bool = True
    ) -> Dict[str, Any]:
        """
        Processa input atravÃ©s do sistema completo.
        
        Args:
            input_data: Texto ou embedding
            learn: Se True, atualiza todos os mÃ³dulos
            
        Returns:
            result: Resultado completo do processamento
        """
        result = {
            'timestamp': time.time(),
            'observation_id': self.total_observations
        }
        
        # 1. ObtÃ©m embedding
        if isinstance(input_data, str):
            if self.pipeline is not None:
                pipeline_result = self.pipeline.process_text(input_data, learn=learn)
                embedding = self.pipeline._get_embedding(input_data)
                result['pipeline'] = pipeline_result
            else:
                # Fallback
                np.random.seed(hash(input_data) % (2**32))
                embedding = np.random.randn(self.config.observation_dim)
        else:
            embedding = input_data
            if self.pipeline is not None:
                pipeline_result = self.pipeline.process_embedding(embedding, learn=learn)
                result['pipeline'] = pipeline_result
        
        # 2. Projeta para espaÃ§o do orquestrador se necessÃ¡rio
        if len(embedding) != self.config.state_dim:
            # ProjeÃ§Ã£o simples via pooling
            projected = self._project_observation(embedding)
        else:
            projected = embedding
        
        # 3. Passa pelo orquestrador de Free Energy
        fe_result = self.orchestrator.step(observation=projected)
        result['free_energy'] = fe_result
        
        # 4. Extrai mÃ©tricas chave
        result['F'] = fe_result['F_after']
        result['mode'] = fe_result['mode']
        result['action'] = fe_result.get('action_taken')
        
        self.total_observations += 1
        
        return result
    
    def _project_observation(self, obs: np.ndarray) -> np.ndarray:
        """Projeta observaÃ§Ã£o para dimensÃ£o do espaÃ§o de estados"""
        target_dim = self.config.state_dim
        source_dim = len(obs)
        
        if source_dim == target_dim:
            return obs
        elif source_dim > target_dim:
            # Pooling
            chunk_size = source_dim // target_dim
            reshaped = obs[:chunk_size * target_dim].reshape(target_dim, chunk_size)
            return reshaped.mean(axis=1)
        else:
            # Padding
            padded = np.zeros(target_dim)
            padded[:source_dim] = obs
            return padded
    
    def get_system_status(self) -> Dict[str, Any]:
        """Status completo do sistema"""
        status = {
            'total_observations': self.total_observations,
            'free_energy': self.orchestrator.get_system_health()
        }
        
        if self.pipeline is not None:
            status['pipeline'] = self.pipeline.get_system_status()
        
        return status
    
    def get_recommendation(self) -> Dict[str, Any]:
        """
        ObtÃ©m recomendaÃ§Ã£o do sistema sobre prÃ³xima aÃ§Ã£o.
        
        Combina Active Inference com anÃ¡lise de Free Energy.
        """
        health = self.orchestrator.get_system_health()
        
        # Seleciona aÃ§Ã£o via EFE
        action, action_info = self.orchestrator.efe.select_action()
        
        # Gera explicaÃ§Ã£o
        explanation = self._generate_explanation(health, action, action_info)
        
        return {
            'recommended_action': action,
            'action_info': action_info,
            'system_status': health['status'],
            'explanation': explanation,
            'F_current': health['F_current']
        }
    
    def _generate_explanation(
        self,
        health: Dict,
        action: str,
        action_info: Dict
    ) -> str:
        """Gera explicaÃ§Ã£o em linguagem natural"""
        status = health['status']
        
        explanations = {
            'explore': f"Sistema sugere EXPLORAR. Status: {status}. "
                      f"Buscar novos conhecimentos para reduzir incerteza.",
            'exploit': f"Sistema sugere EXPLOITAR. Status: {status}. "
                      f"Aprofundar em Ã¡reas jÃ¡ conhecidas.",
            'query': f"Sistema sugere QUERY. Status: {status}. "
                    f"Fazer busca direcionada para preencher gaps.",
            'consolidate': f"Sistema sugere CONSOLIDAR. Status: {status}. "
                          f"Integrar conhecimentos antes de expandir.",
            'rest': f"Sistema sugere PAUSAR. Status: {status}. "
                   f"Permitir settling dos estados internos."
        }
        
        return explanations.get(action, f"AÃ§Ã£o: {action}. Status: {status}")
    
    def save_state(self) -> str:
        """Salva estado completo"""
        self.orchestrator.save_state()
        if self.pipeline is not None:
            self.pipeline.save_state()
        return self.config.save_path
    
    def load_state(self) -> bool:
        """Carrega estado"""
        loaded = self.orchestrator.load_state()
        if self.pipeline is not None:
            self.pipeline.load_state()
        return loaded


# =============================================================================
# FACTORY FUNCTIONS
# =============================================================================

def create_free_energy_system(
    state_dim: int = 64,
    observation_dim: int = 384,
    embedding_model: Optional[Any] = None,
    vqvae: Optional[Any] = None,
    mycelial: Optional[Any] = None,
    load_existing: bool = True
) -> AlexandriaFreeEnergySystem:
    """
    Factory function para criar sistema completo de Free Energy.
    """
    config = FreeEnergyConfig(
        state_dim=state_dim,
        observation_dim=observation_dim
    )
    
    system = AlexandriaFreeEnergySystem(
        config=config,
        embedding_model=embedding_model,
        vqvae=vqvae,
        mycelial=mycelial
    )
    
    if load_existing:
        loaded = system.load_state()
        if loaded:
            print(f"âœ… Free Energy System carregado: timestep {system.orchestrator.timestep}")
        else:
            print("ğŸŒ± Free Energy System inicializado fresh")
    
    return system


# =============================================================================
# TESTES
# =============================================================================

if __name__ == "__main__":
    print("=" * 70)
    print("FREE ENERGY PRINCIPLE - ALEXANDRIA")
    print("=" * 70)
    
    # Criar sistema
    config = FreeEnergyConfig(state_dim=64, observation_dim=64)
    orchestrator = FreeEnergyOrchestrator(config)
    
    # Simular observaÃ§Ãµes
    print("\nğŸ”„ SIMULANDO CICLOS DE FREE ENERGY...")
    
    for i in range(30):
        # ObservaÃ§Ã£o simulada
        obs = np.random.randn(64)
        
        # Passo do orquestrador
        result = orchestrator.step(observation=obs)
        
        if i % 5 == 0:
            print(f"\n   Timestep {result['timestep']}:")
            print(f"      Mode: {result['mode']}")
            print(f"      F: {result['F_before']:.3f} â†’ {result['F_after']:.3f}")
            if result.get('action_taken'):
                print(f"      Action: {result['action_taken']}")
    
    # Health check
    print("\nğŸ“Š SAÃšDE DO SISTEMA:")
    health = orchestrator.get_system_health()
    print(f"   Status: {health['status']}")
    print(f"   DiagnÃ³stico: {health['diagnosis']}")
    print(f"   F mÃ©dio: {health['F_mean']:.3f} Â± {health['F_std']:.3f}")
    print(f"   TendÃªncia: {health['F_trend']}")
    print(f"   AÃ§Ãµes: {health['action_distribution']}")
    
    # Teste do sistema completo
    print("\nğŸ§  TESTANDO SISTEMA COMPLETO...")
    
    # Usa dimensÃµes compatÃ­veis com o pipeline (384D para observaÃ§Ãµes)
    full_config = FreeEnergyConfig(state_dim=64, observation_dim=384)
    system = AlexandriaFreeEnergySystem(full_config)
    
    for i in range(10):
        # ObservaÃ§Ã£o com dimensÃ£o correta para o pipeline
        obs = np.random.randn(384)
        obs = obs / np.linalg.norm(obs)  # Normaliza
        result = system.process(obs)
        
        if i % 3 == 0:
            print(f"   Obs {i}: F={result['F']:.3f}, mode={result['mode']}")
    
    # RecomendaÃ§Ã£o
    print("\nğŸ¯ RECOMENDAÃ‡ÃƒO:")
    rec = system.get_recommendation()
    print(f"   AÃ§Ã£o: {rec['recommended_action']}")
    print(f"   ExplicaÃ§Ã£o: {rec['explanation']}")
    
    # Salvar
    save_path = system.save_state()
    print(f"\nğŸ’¾ Estado salvo em: {save_path}")
    
    print("\n" + "=" * 70)
    print("âœ… FREE ENERGY PRINCIPLE IMPLEMENTADO")
    print("=" * 70)
    
    print("""
    
HIERARQUIA COMPLETA:
====================

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    FREE ENERGY PRINCIPLE                       â”‚
    â”‚                                                                â”‚
    â”‚   F = Complexity - Accuracy                                    â”‚
    â”‚   F = D_KL[Q(s)||P(s)] - E_Q[log P(o|s)]                      â”‚
    â”‚                                                                â”‚
    â”‚   Minimizar F unifica TUDO:                                    â”‚
    â”‚                                                                â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
    â”‚   â”‚ PERCEPÃ‡ÃƒO   â”‚  â”‚   AÃ‡ÃƒO      â”‚  â”‚ APRENDIZADO â”‚           â”‚
    â”‚   â”‚             â”‚  â”‚             â”‚  â”‚             â”‚           â”‚
    â”‚   â”‚ Atualiza    â”‚  â”‚ Muda o      â”‚  â”‚ Melhora     â”‚           â”‚
    â”‚   â”‚ Q(s) para   â”‚  â”‚ mundo para  â”‚  â”‚ P(o,s)      â”‚           â”‚
    â”‚   â”‚ explicar o  â”‚  â”‚ o ser mais  â”‚  â”‚ para se     â”‚           â”‚
    â”‚   â”‚             â”‚  â”‚ provÃ¡vel    â”‚  â”‚ ajustar     â”‚           â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜           â”‚
    â”‚          â”‚                â”‚                â”‚                   â”‚
    â”‚          â–¼                â–¼                â–¼                   â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
    â”‚   â”‚           ORQUESTRADOR DE FREE ENERGY           â”‚         â”‚
    â”‚   â”‚                                                 â”‚         â”‚
    â”‚   â”‚  â€¢ Monitora F global                           â”‚         â”‚
    â”‚   â”‚  â€¢ Decide modo (percepÃ§Ã£o/aÃ§Ã£o/aprendizado)    â”‚         â”‚
    â”‚   â”‚  â€¢ Adapta thresholds dinamicamente             â”‚         â”‚
    â”‚   â”‚  â€¢ Reporta "saÃºde" do sistema                  â”‚         â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                   MÃ“DULOS IMPLEMENTADOS                        â”‚
    â”‚                                                                â”‚
    â”‚   âœ… Hebbian          - Energia local                         â”‚
    â”‚   âœ… Meta-Hebbian     - Aprende regras de aprendizado         â”‚
    â”‚   âœ… Predictive Coding - Minimiza erro de prediÃ§Ã£o            â”‚
    â”‚   âœ… Active Inference  - Age para minimizar E[F]              â”‚
    â”‚   âœ… Free Energy       - PrincÃ­pio unificador                 â”‚
    â”‚   âœ… Integration Layer - Cola tudo                            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


STATUS DO SISTEMA:
==================

    OPTIMAL    : F < target          (equilÃ­brio)
    HEALTHY    : F < threshold_action (funcionando bem)
    STRESSED   : F < threshold_perc   (precisa percepÃ§Ã£o)
    CRITICAL   : F > threshold_perc   (em dificuldade)


USO:
====

    from free_energy import create_free_energy_system
    
    # Criar sistema completo
    system = create_free_energy_system(
        embedding_model=model,
        vqvae=monolith,
        mycelial=mycelial_net
    )
    
    # Processar
    result = system.process("Vector quantization paper...")
    print(f"Free Energy: {result['F']}")
    print(f"Mode: {result['mode']}")
    
    # Status
    status = system.get_system_status()
    print(f"Health: {status['free_energy']['status']}")
    
    # RecomendaÃ§Ã£o
    rec = system.get_recommendation()
    print(f"SugestÃ£o: {rec['recommended_action']}")
    print(f"ExplicaÃ§Ã£o: {rec['explanation']}")
    
    """)
